# Server Configuration
host: "0.0.0.0"
port: 8000

# CORS Configuration
allowed_origins:
  - "http://localhost:3000"
  - "http://localhost:8080"
  - "*" # For development only

# LLM Configuration
model_name: "gemini-2.0-flash"
max_tokens: 1000

# GraphRAG Configuration (tunable)
graphrag:
  # Number of items to retrieve for vector search (used in fallback and hints)
  top_k: 8
  # Fallback vector search k when GraphRAG LLM path is unavailable
  fallback_top_k: 5
  # Soft timeout in seconds for RAG operations (best-effort)
  request_timeout_seconds: 60
  # Max context tokens (hint for trimming, best-effort)
  max_context_tokens: 8192
  # Add a workspace scoping prelude in the prompt
  prelude_enabled: true
  # Restrict retrieval strictly to the active workspace
  workspace_scope: true
  # Adds debug information to the response
  debug_output: false
